import streamlit as st
import pandas as pd
import os, io, tempfile, time
from dotenv import load_dotenv
from parser import parse_special_excel
from db import get_engine, list_tables, make_columns, create_table, load_dataframe, set_column_comments
from validator import coerce_df
import copy
from profiles import list_profiles, save_profile, delete_profile
from history import add_record, list_records, get_record, save_dataframe_csv, update_record

st.set_page_config(page_title="–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö ‚Üí –ë–î", page_icon="üß©", layout="wide")
st.title("üß© –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö: Excel ‚Üí –ë–î")

load_dotenv()

# --- Profiles section ---
with st.sidebar:
    st.header("–ü—Ä–æ—Ñ–∏–ª–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π")
    profs = list_profiles()
    names = ["<–Ω–µ –≤—ã–±—Ä–∞–Ω>"] + [p["name"] for p in profs]
    selected_name = st.selectbox("–ü—Ä–æ—Ñ–∏–ª—å", options=names, index=0)
    if selected_name != "<–Ω–µ –≤—ã–±—Ä–∞–Ω>":
        prof = next(p for p in profs if p["name"] == selected_name)
        default_url = prof["db_url"]
        default_schema = prof["schema"]
    else:
        default_url = os.getenv("DB_URL", "postgresql+psycopg2://analytics:analytics@158.160.43.121:15432/load_excel?sslmode=prefer")
        default_schema = os.getenv("DB_SCHEMA", "public")

    db_url = st.text_input("DB URL", value=default_url)
    db_schema = st.text_input("Schema", value=default_schema)

    colp1, colp2 = st.columns(2)
    with colp1:
        new_name = st.text_input("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ –ø—Ä–æ—Ñ–∏–ª—å (–∏–º—è)", placeholder="prod-load-excel")
    with colp2:
        if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å", use_container_width=True, disabled=not new_name or not db_url):
            save_profile(new_name, db_url, db_schema or "")
            st.success(f"–ü—Ä–æ—Ñ–∏–ª—å '{new_name}' —Å–æ—Ö—Ä–∞–Ω—ë–Ω")

    if selected_name != "<–Ω–µ –≤—ã–±—Ä–∞–Ω>":
        if st.button("–£–¥–∞–ª–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å", use_container_width=True):
            delete_profile(selected_name)
            st.success(f"–ü—Ä–æ—Ñ–∏–ª—å '{selected_name}' —É–¥–∞–ª—ë–Ω. –û–±–Ω–æ–≤–∏—Ç–µ —Å–ø–∏—Å–æ–∫ (–ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É).")

    st.divider()
    connect = st.button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ / –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü")

tables = []
engine = None
if connect:
    try:
        engine = get_engine(db_url)
        tables = list_tables(engine, db_schema or None)
        st.session_state["db_url"] = db_url
        st.session_state["db_schema"] = db_schema
        st.session_state["tables"] = tables
        st.success(f"–û–∫! –ù–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(tables)}")
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")

# --- File upload & parse ---
st.subheader("1) –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞")
file_format = st.selectbox("–¢–∏–ø —Ñ–∞–π–ª–∞", ["Excel —Å–æ —Å–ø–µ—Ü-—à–∞–ø–∫–æ–π (3 —Å—Ç—Ä–æ–∫–∏)", "–û–±—ã—á–Ω—ã–π Excel/CSV (–ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –∑–∞–≥–æ–ª–æ–≤–∫–∏)"], index=0)
f = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel (.xlsx) –∏–ª–∏ CSV", type=["xlsx","csv"])

schema = None
df_raw = None
if f:
    try:
        if file_format == "Excel —Å–æ —Å–ø–µ—Ü-—à–∞–ø–∫–æ–π (3 —Å—Ç—Ä–æ–∫–∏)" and f.name.endswith(".xlsx"):
            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx")
            tmp.write(f.read()); tmp.close()
            schema, df_raw = parse_special_excel(tmp.name)
            os.unlink(tmp.name)
            st.success("–§–∞–π–ª —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω –ø–æ —à–∞–±–ª–æ–Ω—É —Å–æ —Å–ø–µ—Ü-—à–∞–ø–∫–æ–π.")
        else:
            if f.name.endswith(".csv"):
                df_raw = pd.read_csv(f)
            else:
                df_raw = pd.read_excel(f)
            schema = [{"column": c, "description": "", "source_type": "", "sql_type_suggested": "TEXT"} for c in df_raw.columns]
            st.info("–û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º (–ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –∑–∞–≥–æ–ª–æ–≤–∫–∏).")
        st.write("**–°—Ö–µ–º–∞ ‚Äî —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤:**")
        schema_edit = copy.deepcopy(schema)
        type_options = ["TEXT","NUMERIC","TIMESTAMP","BOOLEAN"]
        for col in schema_edit:
            col["sql_type_suggested"] = st.selectbox(
                f"–¢–∏–ø –¥–ª—è '{col['column']}'",
                type_options,
                index=type_options.index(col.get("sql_type_suggested","TEXT")) if col.get("sql_type_suggested","TEXT") in type_options else 0,
                key=f"type_{col['column']}"
            )
        schema = schema_edit
        st.dataframe(pd.DataFrame(schema))
        st.write("**–ü—Ä–µ–≤—å—é –¥–∞–Ω–Ω—ã—Ö:**")
        st.dataframe(df_raw.head(50))
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ —Ñ–∞–π–ª–∞: {e}")

st.divider()
st.subheader("2) –¢–∞–±–ª–∏—Ü–∞ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è")

db_url = st.session_state.get("db_url", db_url)
db_schema = st.session_state.get("db_schema", db_schema)
tables = st.session_state.get("tables", tables)

col1, col2 = st.columns(2)
with col1:
    choice = st.radio("–í—ã–±–æ—Ä —Ç–∞–±–ª–∏—Ü—ã:", ["–í—ã–±—Ä–∞—Ç—å –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö", "–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é"], horizontal=True)
    if choice == "–í—ã–±—Ä–∞—Ç—å –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö":
        table_name = st.selectbox("–¢–∞–±–ª–∏—Ü–∞", options=tables) if tables else st.text_input("–ò–º—è —Ç–∞–±–ª–∏—Ü—ã")
    else:
        table_name = st.text_input("–ò–º—è –Ω–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã", placeholder="–Ω–∞–ø—Ä–∏–º–µ—Ä: dim_items")
with col2:
    load_mode = st.selectbox("–†–µ–∂–∏–º –∑–∞–≥—Ä—É–∑–∫–∏", ["append", "replace"], index=0)
    chunk = st.number_input("–†–∞–∑–º–µ—Ä –ø–∞—á–∫–∏ (chunksize)", min_value=100, max_value=50000, value=5000, step=100)

from sql_preview import ddl_create, dml_insert_preview, replace_plan

if schema and table_name:
    st.markdown("**SQL-–ø—Ä–µ–≤—å—é:**")
    st.code(ddl_create(db_schema or None, table_name, schema), language="sql")
    st.code(dml_insert_preview(db_schema or None, table_name, [c["column"] for c in schema]), language="sql")
    if load_mode == "replace":
        st.code(replace_plan(db_schema or None, table_name), language="sql")

if st.button("–ó–∞–≥—Ä—É–∑–∏—Ç—å", disabled=not (schema and table_name and db_url)):
    try:
        engine = get_engine(db_url)
        columns = make_columns(schema)
        ok, msg = create_table(engine, db_schema or None, table_name, columns)
        if ok:
            st.success(msg)
            okc, msgc = set_column_comments(engine, db_schema or None, table_name, schema)
            if okc:
                st.info(msgc)
            else:
                st.warning(msgc)
        else:
            st.error(msg)
        # if ok:
        #     try:
        #         # st.success(msg)
        #         st.session_state["tables"] = list_tables(engine, db_schema or None)
        #     except Exception:
        #         st.error(msg)
        #         pass
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞: {e}")

st.divider()
st.subheader("3) –ü—Ä–∞–≤–∏–ª–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö")
req_cols = st.multiselect("–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (NOT NULL)", options=[c["column"] for c in (schema or [])])
uniq_cols = st.multiselect("–£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º (—Å–æ—Å—Ç–∞–≤–Ω–æ–π –∫–ª—é—á)", options=[c["column"] for c in (schema or [])])

st.divider()
st.subheader("4) –í–∞–ª–∏–¥–∞—Ü–∏—è, –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –∏—Å—Ç–æ—Ä–∏—è")

colA, colB = st.columns(2)
with colA:
    do_load = st.button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å", disabled=not (schema and df_raw is not None and table_name and db_url))
with colB:
    st.caption("–ò—Å—Ç–æ—Ä–∏—è –∑–∞–≥—Ä—É–∑–æ–∫ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 –∑–∞–ø–∏—Å–µ–π)")

if do_load:
    try:
        engine = get_engine(db_url)
        df_ok, df_err = coerce_df(df_raw, schema, req_cols, uniq_cols)

        c1, c2, c3 = st.columns(3)
        with c1: st.metric("–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫", len(df_raw) if df_raw is not None else 0)
        with c2: st.metric("–í–∞–ª–∏–¥–Ω–æ", len(df_ok))
        with c3: st.metric("–û—à–∏–±–∫–∏", len(df_err))

        # create history record
        rec_id = add_record({
            "ts": int(time.time()),
            "db_url": db_url,
            "schema": db_schema,
            "table": table_name,
            "mode": load_mode,
            "rules": {"required": req_cols, "unique": uniq_cols},
            "filename": getattr(f, "name", ""),
        })

        if not df_err.empty:
            st.warning("–ù–∞–π–¥–µ–Ω—ã –æ—à–∏–±–∫–∏. –≠—Ç–∏ —Å—Ç—Ä–æ–∫–∏ –ù–ï –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
            st.dataframe(df_err.head(200))
            err_path = save_dataframe_csv(rec_id, df_err, "err")
            st.info(f"–û—Ç—á—ë—Ç –æ–± –æ—à–∏–±–∫–∞—Ö —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {err_path}")
            st.download_button("–°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç –æ–± –æ—à–∏–±–∫–∞—Ö (CSV)", data=df_err.to_csv(index=False).encode("utf-8"), file_name=f"{rec_id}_errors.csv", mime="text/csv")
            update_record(rec_id, {"errors_csv": err_path, "errors_count": int(len(df_err))})

        if not df_ok.empty:
            ok, msg = load_dataframe(engine, db_schema or None, table_name, df_ok, mode=load_mode, chunksize=int(chunk))
            if ok:
                st.success(msg)
            else:
                st.error(msg)
            if ok:
                ok_path = save_dataframe_csv(rec_id, df_ok, "ok")
                update_record(rec_id, {"ok_csv": ok_path, "ok_count": int(len(df_ok)), "status": "loaded"})
            else:
                update_record(rec_id, {"status": "failed", "error": msg})
        else:
            st.info("–í–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –Ω–µ—Ç ‚Äî –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞.")
            update_record(rec_id, {"status": "no_valid_rows"})

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞: {e}")

# History panel
st.subheader("–ò—Å—Ç–æ—Ä–∏—è –∑–∞–≥—Ä—É–∑–æ–∫")
records = list_records(limit=50)
if not records:
    st.info("–ò—Å—Ç–æ—Ä–∏—è –ø–æ–∫–∞ –ø—É—Å—Ç–∞.")
else:
    import datetime
    rows = []
    for r in records:
        ts = datetime.datetime.fromtimestamp(r.get("ts", 0)).strftime("%Y-%m-%d %H:%M:%S")
        rows.append({
            "id": r.get("id"),
            "time": ts,
            "table": f"{r.get('schema')}.{r.get('table')}" if r.get("schema") else r.get("table"),
            "mode": r.get("mode"),
            "ok": r.get("ok_count", 0),
            "errors": r.get("errors_count", 0),
            "file": r.get("filename", ""),
            "status": r.get("status", ""),
        })
    st.dataframe(pd.DataFrame(rows))

    st.markdown("**–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É –ø–æ –∑–∞–ø–∏—Å–∏ –∏—Å—Ç–æ—Ä–∏–∏**:")
    rec_id_sel = st.selectbox("ID –∑–∞–ø–∏—Å–∏", options=[r["id"] for r in records])
    if st.button("–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É —ç—Ç–æ–π –∑–∞–ø–∏—Å–∏", disabled=not rec_id_sel):
        rec = get_record(rec_id_sel)
        if rec and rec.get("ok_csv"):
            try:
                engine = get_engine(st.session_state.get("db_url", db_url))
                df_ok = pd.read_csv(rec["ok_csv"])
                ok, msg = load_dataframe(engine, rec.get("schema") or None, rec.get("table"), df_ok, mode=rec.get("mode","append"), chunksize=5000)
                st.success(f"[Re-run] {msg}")
                if ok:
                    st.success(f"[Re-run] {msg}")
                else:
                    st.error(f"[Re-run] {msg}")
            except Exception as e:
                st.error(f"[Re-run] –û—à–∏–±–∫–∞: {e}")
        else:
            st.warning("–£ –∑–∞–ø–∏—Å–∏ –Ω–µ—Ç —Ñ–∞–π–ª–∞ –≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫.")
